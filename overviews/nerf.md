---
layout: page
title: מבוא מזורז ל-Neural Radiance Fields (NeRF)
---

מטרת הפוסט הארוך הזה היא לשמש כמבוא קצר לתחום מחקר חדש (ולוהט) היושב באחת מנקודות ההשקה של למידה עמוקה, גרפיקה ועיבוד אותות, אך פחות מוכר בקרב הקהילה, נכון לעכשיו. מדובר בתחום הצומח הנקרא Neural Radiance Fields או בקיצור NeRF, אשר שם לו למטרה לייצג ולשחזר אותות תלת מימדיים המיוצגים בצורה סתומה (implicit). משמעות הדבר היא שאין לנו יכולת לקשר באופן ישיר בין הייצוג לבין הסצינה המיוצגת, אלא שאנחנו בונים מודל שניתן באמצעותו לשאול שאלות מסויימות על האובייקט או הסצינה.

![]({{ site.baseurl }}/assets/nerf/NeRF_Flow.png)

אומנם המטרה העיקרית כאן היא הצגת הסצינה מכל מרחק וכל זווית צפיה (novel view synthesis), המודלים הללו פותחים את הדלת לעוד שימושים מעניינים, כמיטב המסורת בעולם הדאטה.

בפוסט זה אסקור בקצרה כמה מאמרים חשובים בתחום, בלי להיכנס יותר מדי לפרטים הטכניים כמו פונקציות הלוס, הארכיטקטורות, האימון וכו׳.

## Neural Volumes (2019)

במאמר זה של [Lombardi et al](https://arxiv.org/abs/1906.07751) מ-2019, אובייקט תלת מימדי מיוצג באמצעות חלוקה לפיקסלים תלת מימדיים (ווקסלים).

![Neural Volumes]({{ site.baseurl }}/assets/nerf/NV2019.png)

השחזור נעשה באמצעות רשת אשר לומדת לייצג את הצבע וגם שומרת ערך שקיפות יחסית של אותו תא. מכאן, הכותבים משחזרים את האובייקט באמצעות הטלת קרניים מהמצלמה. לצורך כך הם נעזרים באלגוריתם ray-marching שמבצע אינטגרציה של הסיגנל מכל התאים שנחצים ע״י הקרן תוך כדי התחשבות בשקיפות היחסית של כל תא ותא.

 במאמר זה הייצוג חצי סתום ואיכותו מושפעת מאוד מבחירת גודל הדיסקרטיזציה של התאים, ועל החולשה הזאת הכותבים מנסים להתגבר בעזרת רשת שלומדת לבצע אינטרפולציה בין התאים. עם זאת, השיטה עדיין יקרה ואיכות השחזור תלויה במידה רבה במאפייני הדיסקרטיזציה.

## Differentiable Volumetric Rendering (2019)

למרות ששום עבודת מחקר לא נעשית בוואקום, ניתן לזהות את תחילת הקו המחקרי של NeRF באופן סביר עם העבודה [Differentiable Volumetric Rendering](https://avg.is.mpg.de/publications/niemeyer2020cvpr) של Niemeyer et al מ-2019.

![Differentiable Volumetric Rendering]({{ site.baseurl }}/assets/nerf/DVR2019.png)

בעבודה זו ייצגו המחברים את האובייקט המיוצג בצורה סתומה ע״י אימון רשת occupancy שתפקידה להחזיר, עבור הקוד הלטנטי z וקואורדינטות x, y, z את התפוסה בנקודה (יש או אין מידע בנקודה) ומכאן ניתן לשחזר את האובייקט באמצעות שיטות סטנדרטיות לחישוב level-sets. ייחודה של עבודה זו שהיא פותרת את בעיית הייצוג של האובייקט התלת מימדי ללא 3D supervision אלא בעזרת קלט אימון שמורכב מתמונות דו מימדיות בלבד, אך עדיין מסתמכת על גרדיאנטים אנליטיים של תהליך השחזור עצמו, ועדיין יקרה מבחינת מספר הפרמטרים הנדרשים לייצוג האובייקט. עם זאת, התהליך כאן הוא גזיר לחלוטין, כנרמז משם המאמר, ומכאן מתחיל המדרון החלקלק.

## DeepSDF (2019)

בדומה ל-Differentiable Volumetric Rendering, המאמר [DeepSDF](https://arxiv.org/abs/1901.05103) של Park et al מנסה לייצג את האובייקט (במקרה הזה משטח), כפונקציית Signed Distance Function. פונקציה כזאת היא פונקציה הקובעת, עבור כל נקודה במרחב, האם היא מחוץ לאובייקט (1), בתוך האובייקט (-1) או שהיא יושבת בדיוק על שפת האובייקט (0) והמשטח עצמו משוחזר ע״י אלגוריתם למציאת ה-zero level-set של הפונקציה.

![DeepSDF]({{ site.baseurl }}/assets/nerf/DSDF2019.png)

כאמור, גם כאן הרשת המאומנת היא פונקציה שלומדת מידע כלשהו עבור כל נקודה במרחב, אך בניגוד למאמר הקודם שמשתמש בארכיטקטורה מבוססת על autoencoder, פה הכותבים מסתמכים על אימון ה-decoder בלבד על מנת לחסוך משאבי חישוב בזמן האימון. על ארכיטקטורה זו מתבסס המאמר העיקרי שבו עסקינן, Neural Radiance Fields.

## Neural Radiance Fields (2020)

זהו [המאמר](https://arxiv.org/abs/2003.08934) העיקרי של התחום, אשר הוצג בכנס ECCV 2020. כאן, מבקשים המחברים להתגבר על שלושה קשיים מרכזיים בהצגת סצינות תלת מימדיות ריאליסטיות באמצעות דיפ לרנינג:
1. הצגת אובייקטים בעלי מאפיינים לא-למברטיאניים. אובייקט למברטיאני הוא אובייקט אשר משקף את קרני האור הפוגעות בו באותה צורה בדיוק ללא תלות בכיוון, ולמעשה הוא מודל של השתקפות מפזרת (diffusive reflection) אידאלית. אובייקטים כאלה נראים לצופה כמשטחים בצבע ״מט״. במאמר זה הכותבים מעוניינים  לדמות חומרים שאינם אידאליים בהכרח. לצורך כך הכותבים מרחיבים את הקלט של הרשת מ-$\mathbf{x} \in R^3$ וכוללים גם וקטור נוסף $\mathbf{d} \in R^2$ המכיל את זוויות הקרן הנדגמת $\theta, \phi$. כך לומד המודל להתנות את הפלט שלו גם בזווית הצפיה ולא רק במיקום הנדגם בתהליך ה-ray-marching, ובסך הכל מדובר בוקטור בעל חמישה מימדים.
2. פיתוח אלגוריתם דיפרנציאבילי לרינדור האובייקט שמשתמש בידע הקיים כבר מתחום הגרפיקה ובפרט מאפשר להקצות את הפרמטרים של הרשת בצורה יעילה על מנת לייצג את האזורים בסצינה בהם קיים מידע ולא לבזבז קיבולת על האזורים בהם לא קיים מידע.
3. מידול של אובייקטים בעלי גיאומטריה מורכבת שכוללת, בין השאר, תדרים גבוהים, דבר שרשתות עמוקות מתקשות בו בדרך כלל.

### ייצוג הסצינה
הסצינה מיוצגת ע״י האור $\mathbf{c}$ הנפלט מכל נקודה עבור כל זווית צפיה אפשרית (המיוצג ע״י שלשת RGB) וצפיפות $\sigma$ שמשמעותה מהי ההסתברות שהקרן הנדגמת תעצור בחלקיק בגודל אינפיניטסימלי בנקודה $\mathbf{x}$, כלומר שעבור הנקודה $\mathbf{x}$ והזווית $\mathbf{d}$, הנקודה היא אטומה לגמרי. זה בדומה אך שונה למאמר הקודם Neural Volumes. לסיכום, רשת זו לומדת למדל את הפונקציה

$$F_\Theta : (\mathbf{x},\mathbf{d}) \rightarrow \mathbf(c,\sigma)$$

באמצעות המשקלות $\Theta$. רשת זו בבסיסה היא רשת MLP בעלת 8 שכבות FC עם אקטיבציות ReLU, אבל על מנת להבטיח עקביות בצפיה באותה נקודה מזוויות שונות, הרשת מטפלת קודם כל ב-$\mathbf{x}$ ורק בשלב מאוחר יותר ב-$\mathbf{d}$.

![Neural Radiance Fields (NeRF)]({{ site.baseurl }}/assets/nerf/NeRF_Intro.png)

### רינדור/שחזור הסצינה
באופן מדוייק יותר, תהליך הרינדור של פיקסל מסויים בשחזור הסופי הוא שערוך של האינטגרל

$$C(\mathbf{r}) = \int_{t_n}^{t_f}T(t)\sigma(\mathbf{r}(t))\mathbf{c}(\mathbf{r}(t),\mathbf{d})dt$$

כאשר $\mathbf{r}(t)=\mathbf{o}+t\mathbf{d}$ היא הקרן היוצאת מהפיקסל הרלוונטי, $t_n,t_f$ הם גבולות הרינדור הקרוב והרחוק בהתאמה, ו-$T=\text{exp}\left(-\int_{t_n}^{t}\sigma(\mathbf{r}(s))ds\right)$ היא פונקציה המבטאת את הקרינה המצטברת לאורך הקרן עד למרחק $t$, כלומר ההסתברות שהקרן עוברת את המרחק מ-$t_n$ אל $t$ בלי לעצור עקב פגיעה בחלקיק.

אינטגרל זה משוערך באמצעות שיטת quadrature כאשר הדגימות לאורך הקרן מוקצות בצורה אקראית כדי להימנע מאוברפיט לרזולוציית דגימה מסויימת (עוד פרטים - במאמר), ובסך הכל השיטה דיפרנציאבילית.

### פרטים נוספים

בניגוד לנאמר עד כה, הקלט המוזן לרשת הוא לא $(\mathbf{x},\mathbf{d})$ עצמם אלא קידוד מרחבי שלהם, בדומה לנעשה בארכיטקטורת הטרנספורמר (Attention is All You Need), רק שכאן המטרה היא לא להעביר למודל מידע אודות המיקומים היחסיים של אלמנטים, אלא לאפשר לו לעבוד עם תדרים גבוהים ע״י מיפוי הקלט למרחב בעל מימד גבוה יותר הכולל פונקציות קוסינוס וסינוס עם תדרים גבוהים. כך ״עוזרים״ לרשת להתגבר על חוסר היכולת לייצג תדרים גבוהים בעצמה.

בנוסף, המחברים מאמנים רשת נוספת שלומדת לייצג את אותה סצינה ברזולוציה נמוכה יותר (coarse representation) שעליה הם מסתמכים כדי להקצות את הדגימות של האינטגרל: תחילה נדגמת הרשת הגסה ב-$N_c$ נקודות ולאחר מכן מוקצות $N_f$ לדגימה מהרשת העדינה (שעליה דיברנו) בין נקודות הדגימה המקוריות, באופן חכם. כך הכותבים מבקשים להימנע מלדגום את הרשת בנקודות בהן אין מידע.

לסיכום, פונקציית הלוס שעל בסיסה מבצעים את האופטימיזציה של שתי הרשתות (coarse and fine) היא:

$$\mathcal{L}=\sum_{\mathbf{r} \in \mathcal{R}}\bigg[\Vert\hat{C}_c(\mathbf{r})-C(\mathbf{r})\Vert_2^2 + \Vert\hat{C}_f(\mathbf{r})-C(\mathbf{r})\Vert_2^2\bigg]$$

כאשר $\mathbf{r}$ היא קרן מתוך באצ׳ הקרניים $\mathcal{R}$, $C(\mathbf{r})$ היא ה-ground truth ו-$\hat{C}_c, \hat{C}_f$ הן שערוכי האינטגרל לפי הרשתות הגסה והעדינה, בהתאמה.

### מגבלות

כמו שציינתי, זהו תחום מחקר פעיל מאוד, והרבה ממנו כיום מתבסס על המגבלות שבשיטה המוצעת במאמר זה. בין המגבלות שמאמרים אחרים ניסו להתגבר עליהן:

* האימון והשחזור יכולים להיות איטיים מאוד ודורשים הרבה משאבי חישוב,
* המודל אינו מתייחס למימד הזמן ומייצג רק סצינות סטטיות,
* התאורה גם היא קבועה ולא ניתנת לשינוי בזמן הרינדור,
* רשת מאומנת מסוגלת לייצג סצינה אחת בלבד ועל מנת לייצג סצינה נוספת יש לאמן רשת חדשה.

בהמשך נראה כיצד מאמרים חדשים יותר מנסים להתמודד עם חלק מהמגבלות הללו.

## TODO: מאמרים נוספים
1. https://github.com/computational-imaging/automatic-integration AutoInt
1. https://arxiv.org/abs/2103.10380 FastNeRF
1. https://arxiv.org/abs/2010.07492 NeRF++
1. https://github.com/facebookresearch/NSVF Neural Sparse Voxel Fields
1. https://pratulsrinivasan.github.io/nerv/ NeRV
1. https://markboss.me/publication/2021-nerd/ NeRD
1. https://sai-bi.github.io/project/sig21_avatar/index.html Deep Relightable Appearance Models for Animatable Faces
1. https://nerf-w.github.io/ NeRF in the Wild
1. https://marcoamonteiro.github.io/pi-GAN-website/ pi-GAN
1. https://shellguo.com/osf/ Object Centric
1. https://github.com/autonomousvision/graf GRAF
1. https://arxiv.org/abs/2011.12100 GIRAFFE
1. https://arxiv.org/abs/2011.10379 Neural Scene Graphs
1. http://jiataogu.me/style_nerf/ StyleNerF
1. https://alexyu.net/plenoxels/ Plenoxels
1. https://lioryariv.github.io/volsdf/ VolSDF
1. https://lioryariv.github.io/idr/ Disentangling Geometry and Appearance
1. https://github.com/Totoro97/NeuS NeuS
1. https://github.com/computational-imaging/ACORN ACORN